{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertConfig, BertModel\n",
    "import tensorflow as tf\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting TensorFlow checkpoint from /Users/daniter/Documents/jurafsky/conpono/weights/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "conpono = BertModel.from_pretrained(\"../weights/transformers/\")\n",
    "tf_path = \"../weights/model.ckpt\"\n",
    "\n",
    "def get_cpc_weights(tf_checkpoint_path):\n",
    "    tf_path = os.path.abspath(tf_checkpoint_path)\n",
    "    print(\"Converting TensorFlow checkpoint from {}\".format(tf_path))\n",
    "    # Load weights from TF model\n",
    "    init_vars = tf.train.list_variables(tf_path)\n",
    "    excluded = [\"BERTAdam\", \"_power\", \"global_step\", \"_CHECKPOINTABLE_OBJECT_GRAPH\"]\n",
    "    init_vars = list(filter(lambda x: all([True if e not in x[0] else False for e in excluded]), init_vars))\n",
    "    for name, shape in init_vars:\n",
    "        if \"cpc\" not in name:\n",
    "            continue\n",
    "        array = tf.train.load_variable(tf_path, name)\n",
    "        return array\n",
    "    \n",
    "cpc_weights= get_cpc_weights(tf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"First, the opening arguments is made\",\n",
    "        \"This statement is unrelated.\",\n",
    "        \"This statement is also unrelated but it is much longer because it has many words in it.\",\n",
    "        \"Then, the follow up argument is made.\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "def encode_sents(sents):\n",
    "    # encode anchor and continuations\n",
    "    anchor = sents[0]\n",
    "    inputs = [anchor + \" [SEP] \" + s for s in sents[1:]]\n",
    "    inputs = [anchor] + inputs\n",
    "    tokenized_inputs = tokenizer(inputs, return_tensors=\"pt\", add_special_tokens=True, padding=True)\n",
    "    output = conpono(**tokenized_inputs)['pooler_output'].detach()\n",
    "    return output\n",
    "\n",
    "def compute_coherence(encodings, cpc_weights):\n",
    "    cpc_weights = torch.tensor(cpc_weights)[4]\n",
    "    anchor_transform = torch.matmul(encodings[0], cpc_weights)\n",
    "    scores = torch.matmul(encodings[1:], anchor_transform)\n",
    "    return scores.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.3673818 1.2968947 1.3872905]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 0, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = encode_sents(sents)\n",
    "scores = compute_coherence(output, cpc_weights)\n",
    "print(scores)\n",
    "np.argsort(scores)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [\"The first two Sherlock Holmes stories, the novels A Study in Scarlet (1887) and The Sign of the Four (1890), were moderately well received, but Holmes first became very popular early in 1891 when the first six short stories featuring the character were published in The Strand Magazine.\",\n",
    "         \"Holmes became widely known in Britain and America.\",\n",
    "         \"The character was so well-known that in 1893 when Arthur Conan Doyle killed Holmes in the short story \\\"The Final Problem\\\", the strongly negative response from readers was unlike any previous public reaction to a fictional event.\",\n",
    "         \"The Strand reportedly lost more than 20,000 subscribers as a result of Holmes's death.\",\n",
    "         \"Public pressure eventually contributed to Conan Doyle writing another Holmes story in 1901 and resurrecting the character in a story published in 1903.\",\n",
    "         \"In Japan, Sherlock Holmes (and Alice from Alice's Adventures in Wonderland) became immensely popular in the country in the 1890s as it was opening up to the West, and they are cited as two British fictional Victorians who left an enormous creative and cultural legacy there.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.1913104 1.1906443 1.1479765 1.0828052 1.1195012]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 4, 3])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = encode_sents(sents)\n",
    "scores = compute_coherence(output, cpc_weights)\n",
    "print(scores)\n",
    "np.argsort(scores)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conpono",
   "language": "python",
   "name": "conpono"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
